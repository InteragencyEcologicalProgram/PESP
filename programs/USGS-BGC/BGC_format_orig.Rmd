# Format original BGC data

**Purpose:** Code to format BGC data for original PESP upload.

**Author:** Perry ([sarah.perry\@water.ca.gov](mailto:sarah.perry@water.ca.gov){.email})

# Initial Setup

```{r}
# Import Packages ---------------------------------------------------------
library(tidyverse)
library(fuzzyjoin)
library(glue)
library(lubridate)

source('admin/global_functions/global_funcs.R')
source('admin/global_functions/bsa_funcs.R')
source('programs/USGS-BGC/ref_code/bgc_funcs.R')
source('admin/global_functions/check_funcs.R')

options(scipen = 999)
```

```{r}
# Read in Data --------------------------------------------------------------------
# specify the file path
data_path <- abs_pesp_path('Groups/USGS-BGC/01 Raw Data/USGS_Phytoenumeration_2016topresent-20230622ER.csv')

# new data to format and append
df_data <- read_quiet_csv(data_path, col_types = cols(site_no = col_character()))
```

## Check distinct columns
```{r}
# filter duplicate rows with incorrect method (based on provided csv)
df_data <- filter_methods_bgc(df_data)

attr(df_data, 'log')$removed_method_rows
```

```{r}
df_data <- check_distinct(df_data, type = 'full')
nondistinct_rows <- attr(df_data, 'log')$nondistinct_allrows
```

## Rename columns
```{r}
rename_map <- c(
  'Taxon' = 'species',
  'Station' = 'site_no',
  'Biovolume_per_mL' = 'biovolume_um3_per_ml',
  'Cells_per_mL' ='cells_per_ml',
  'SampleMethod' = 'sampler',
  'Latitude' = 'latitude',
  'Longitude' = 'longitude',
  'Comments' = 'notes'
)

df_data <- rename_cols(df_data, rename_map) %>%
  select(-genus)
```

```{r}
unique(df_data$SampleMethod)
```

## Clean up columns
```{r}
df_data <- clean_cols_bgc(df_data)
```

## Remove replicates
```{r}
df_data <- df_data %>% filter(Replicate == FALSE)
```


## Add metadata columns
```{r}
df_data <- add_meta_col(df_data, 'USGS-BGC', 'SampleDepth')

df_data <- add_meta_col(df_data, 'USGS-BGC', 'Lab')
```
## Add lat/lons
```{r}
# remove them as they need updating
df_test <- df_data %>% select(-c(Latitude, Longitude))

df_test <- add_latlon(df_test, 'Groups/USGS-BGC/Metadata/Stations-BGC.csv')
```


# Add Taxonomy (and QC column)

## Correct typos
```{r}
df_data <- correct_taxon_typos(df_data)
corrected_typos <- attr(df_data, 'log')$taxon_corrections
write_log_file(corrected_typos, 'Groups/USGS-BGC/02 Processed Data/QC files/tables/BGC_corrected_typos.csv')

print(corrected_typos)
```


## Add QC column
```{r}
df_data <- add_qc_col(df_data, key_cols = c('Date', 'Time', 'Station', 'SampleMethod'))
df_data <- add_debris_col(df_data)
df_data <- add_notes_col(df_data)

df_data <- extract_unstandardized_comments(df_data, 'Comments', delimiter = '. ')
unmatched_comments <- attr(df_data, 'log')$unmatched_comments
write_log_file(unmatched_comments, 'Groups/USGS-BGC/02 Processed Data/QC files/tables/BGC_leftover_comments.csv')

print(unmatched_comments)
```

## Standardize unknowns
```{r}
df_data <- clean_unknowns(df_data)
standardized_unknowns <- attr(df_data, 'log')$clean_unknowns
write_log_file(standardized_unknowns, 'Groups/USGS-BGC/02 Processed Data/QC files/tables/BGC_standardized_unknowns.csv')

print(standardized_unknowns)
```

## Update synonyms
```{r}
df_data <- update_synonyms(df_data)
updated_synonyms <- attr(df_data, 'log')$synonym_updates
write_log_file(updated_synonyms, 'Groups/USGS-BGC/02 Processed Data/QC files/tables/BGC_updated_synonyms.csv')

print(updated_synonyms)
```

## Add in higher-level taxa
```{r}
df_data <- higher_lvl_taxa(df_data)
needs_hierarchy <- attr(df_data, 'log')$unmatched_taxa
write_log_file(needs_hierarchy, 'Groups/USGS-BGC/02 Processed Data/QC files/tables/BGC_needs_hierarchy.csv')

print(needs_hierarchy)
```

## Subset columns
```{r}
df_data <- subset_cols_bgc(df_data)
```

## Check distinct cols before combining
```{r}
df_data <- check_distinct(df_data, type = 'full')
attr(df_data, 'log')$nondistinct_allrows

df_data <- check_distinct(df_data, type = 'key_measure_cols', key_cols = c('Station','Date', 'Time'), measurement_cols = c('Biovolume_per_mL','Cells_per_mL'))
nondistinct_rows <- attr(df_data, 'log')$nondistinct_keymeasurerows
write_log_file(nondistinct_rows, 'Groups/USGS-BGC/02 Processed Data/QC files/tables/BGC_nondistinct_rows.csv')

nondistinct_rows

# Remove rows with "Submersible centrifugal pump" or "'Peristaltic pump" as SampleMethod that aren't distinct
df_data <- df_data %>%
  anti_join(
    nondistinct_rows %>%
      filter(SampleMethod == c('Submersible centrifugal pump','Peristaltic pump')),
    by = c('Station', 'Date', 'Time')
  )

df_data <- check_distinct(df_data, type = 'key_measure_cols', key_cols = c('Station','Date', 'Time'), measurement_cols = c('Biovolume_per_mL','Cells_per_mL'))
```

## Change 0 to NA
```{r}
df_data$Cells_per_mL[df_data$Cells_per_mL == 0] <- NA
df_data$Biovolume_per_mL[df_data$Biovolume_per_mL == 0.00] <- NA
```

## Remove data where both Cells per mL and Biovolume per mL are NA
```{r}
df_data <- df_data %>%
  filter(
    !(is.na(Cells_per_mL) & is.na(Biovolume_per_mL))
  )
```


## Combine taxa (multiple sizes, standardized unknowns)
```{r}
df_data <- combine_taxons(df_data, key_cols = c('Date', 'Time', 'Station', 'SampleDepth'))
combined_taxa <- attr(df_data, 'log')$combined_taxa
write_log_file(combined_taxa, 'Groups/USGS-BGC/02 Processed Data/QC files/tables/BGC_combined_taxa.csv')

print(combined_taxa)
```

# Checks

## Check NAs
```{r}
df_data <- check_nas(df_data)
na_check <- attr(df_data, 'log')$na_check

print(na_check)
```

## Check methods
```{r}
unique_check(df_data, SampleMethod)
```

## Check stations
```{r}
unique_check(df_data, Station)
```

## Export
```{r}
write_csv(df_data, abs_pesp_path('Groups/USGS-BGC/02 Processed Data/BGC_draft.csv'))
```
