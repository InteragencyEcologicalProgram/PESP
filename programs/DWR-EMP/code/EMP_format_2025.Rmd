# Format EMP Phytoplankton Data

**Purpose:** Code to format and append new EMP phytoplankton data to the current EDI data set.

**Author:** Perry ([sarah.perry\@water.ca.gov](mailto:sarah.perry@water.ca.gov){.email})

**Date Edited:** 04/30/2025

## Variables to Edit

```{r}
# specify the file path of the new data (as a csv)
data_path <- 'programs/DWR-EMP/ref_data/emp_2023.xlsx'
```

## Formatting Code (Don't Edit)

Hit the green arrow on the right side of the code to run.

**Output:** a .csv containing the formatted data (ready for EDI publication)

If errors occur, contact Sarah Perry.

```{r}
# Import Packages ---------------------------------------------------------
library(tidyverse)
library(fuzzyjoin)
library(glue)
library(hms)
library(lubridate)
source('admin/global_functions/global_funcs.R') # TODO: suppress messages
source('admin/global_functions/bsa_funcs.R')
source('admin/global_functions/check_funcs.R')
source('programs/DWR-EMP/code/EMP_funcs.R')

# Read in Data ------------------------------------------------------------

# data frame containing Tiffany Browns's standardized phyto taxa csv
df_syn <- read_quiet_csv('admin/global_data/phyto_classifications.csv')

# new data to format and append
df_data <- read_bsa_xlsx(data_path)

# read in station names
df_stations <- read_quiet_csv('programs/DWR-EMP/ref_data/EMP_phyto_stations.csv')

# read in WQ data to merge datetimes
df_wq <- get_edi_file(458, glue::glue('EMP_DWQ_1975_2023'))
df_wq <- df_wq[[1]]

# Standardize Current Columns ---------------------------------------------
# # functions found in 'bsa_funcs.R'

# standardize column names
# # removes unnecessary cols
# # dds reporting unit cols
df_data <- standardize_cols(df_data)

# correctly identify NA values in PhytoForm
df_data <- clean_phytoform(df_data)

# format time
df_data$Time <- sapply(df_data$Time, function(x) format(x, format='%H:%M'))

df_data <- df_data %>%
  mutate(Time = paste0(Time,':00'))

df_data$Time <- parse_hms(df_data$Time)

# filter wq by correct year (not rly needed)
df_wqyear <- df_wq %>% filter(year(Date) == 2023)
```

```{r}
# check dates/times match up; manually fix
# Error in (function (..., row.names = NULL, check.rows = FALSE, check.names = TRUE,  :
# means that they're the same
dplyr::anti_join(df_data, df_wqyear, by = c('Station', 'Date','Time')) %>%
  select(Lab:Station) %>%
  unique()
```

```{r}
# add in lat/lon
df_data <- left_join(df_data, df_wqyear[c('Station','Date','Time','Latitude','Longitude')], by = c('Station','Date','Time')) %>%
  relocate(c('Latitude','Longitude'), .after = 'Station')
```

```{r}
# Standardize Data Set ------------------------------------------------------------

# # Clean Station Names -----------------------------------------------------------
df_data$Station <- fix_station_typos(df_data$Station)

# check for typos
# # add in EZs for logical check
ls_extras <- c('EZ2','EZ6','EZ6-SJR','EZ2-SJR')
ls_all_stats <- c(unique(df_stations$Station), ls_extras)

# # check
check_stations(df_data$Station, ls_all_stats)

# # Clean Unknown Identifiers -----------------------------------------------------
df_data <- clean_unknowns(df_data)

# # Add in Higher Level Taxa ------------------------------------------------------
df_joined <- higher_lvl_taxa(df_data, 'Longitude')

df_newtaxa <- check_higher_taxa(df_joined)

# write_csv(df_newtaxa, 'programs/DWR-EMP/generated_data/new_taxa.csv')

# # Update Names ------------------------------------------------------------------
df_joined <- update_synonyms(df_joined)

check_synonyms(df_joined)
```

```{r}
library(tidyverse)
#' @title Standardize Unknown Taxon Labels
#'
#' @description
#' This function standardizes taxon names by:
#' - Converting 'spp.' to 'sp.'
#' - Normalizing unknown-like terms to 'Unknown'
#' - Removing trailing numbers in taxon names
#' Logs any changes applied to the `Taxon` column.
#'
#' @param df A dataframe containing `Taxon` and `Species` columns to clean
#'
#' @return A dataframe with updated `Taxon` and `Species` columns, and a 'log' attribute tracking changes
#'
#' @importFrom stringr str_replace_all str_replace
clean_unknowns <- function(df) {
  original_taxon <- df$Taxon
  
  unknown_syns <- 'unknown|unidentified|undetermined'
  df$Taxon <- dplyr::case_when(
    grepl(unknown_syns, df$Taxon, ignore.case = TRUE) ~ stringr::str_replace_all(df$Taxon, regex(unknown_syns, ignore_case = TRUE), 'Unknown'),
    TRUE ~ df$Taxon
  )
  
  df$Taxon <- stringr::str_replace_all(df$Taxon, 'spp\\.', 'sp.')

  df$Taxon <- stringr::str_replace(df$Taxon, 'sp\\..*', 'sp.')

  df$Taxon <- gsub('\\s+\\d+$', '', df$Taxon)

  log_df <- tibble::tibble(
    row = which(original_taxon != df$Taxon),
    old_Taxon = original_taxon[original_taxon != df$Taxon],
    new_Taxon = df$Taxon[original_taxon != df$Taxon],
  )
  
  message('Unique unknown taxon standardized: ', nrow(log_df))
  attr(df, 'log') <- list(clean_unknowns = log_df)
  return(df)
}

#' @title Correct Taxon Names Using a Typo Lookup Table
#'
#' @description
#' Corrects known taxon name typos based on an external lookup table with known errors.
#' Replaces incorrect entries with their corrected forms and logs changes.
#'
#' @param df A dataframe with a Taxon column to check for typos
#' @param typo_file Path to a CSV file containing columns Taxon and TaxonCorrected
#'
#' @return A dataframe with corrected Taxon names and a 'log' attribute containing taxon_corrections
#'
#' @importFrom dplyr left_join mutate select coalesce filter
#' @importFrom readr read_csv
correct_taxon_typos <- function(df) {
  df_typos <- df_typos #read_quiet_csv('admin/global_data/common_typos.csv')
  
  df <- df %>%
    left_join(df_typos, by = 'Taxon')
  
  if ('TaxonCorrected' %in% names(df) && any(!is.na(df$TaxonCorrected))) {
    typo_log <- df %>%
      filter(!is.na(TaxonCorrected) & TaxonCorrected != Taxon) %>%
      select(Date, Station, original_Taxon = Taxon, corrected_Taxon = TaxonCorrected)
    message('Known typos corrected: ', nrow(typo_log))
  } else {
    typo_log <- tibble::tibble()
    message('No known taxon typos found.')
  }
  
  df <- df %>%
    mutate(Taxon = coalesce(TaxonCorrected, Taxon)) %>%
    select(-TaxonCorrected)
  
  attr(df, 'log') <- list(taxon_corrections = typo_log)
  return(df)
}

#' @title Update Taxon Names to Reflect Current Synonym Metadata
#'
#' @description
#' Updates outdated taxon names to their current standardized forms using a synonym chain
#' from a metadata file. Preserves the original name in a new column and logs all replacements.
#'
#' @param df A dataframe with a `Taxon` column to standardize using synonym metadata
#'
#' @return A dataframe with current Taxon values and an OrigTaxon column (if changed),
#' plus a log attribute with synonym updates
#'
#' @importFrom dplyr mutate select left_join relocate any_of
update_synonyms <- function(df) {
  df_syn <- df_syn %>% #read_quiet_csv('admin/global_data/phyto_classifications.csv') %>%
    select(c('Taxon','CurrentTaxon')) %>%
    rename(PureTaxon = Taxon)
  
  synonym_map <- setNames(as.character(df_syn$CurrentTaxon), df_syn$PureTaxon)
  
  newest_taxon <- function(taxon) {
    while (!is.na(synonym_map[taxon]) && synonym_map[taxon] != 'None') {
      taxon <- synonym_map[taxon]
    }
    return(taxon)
  }
  
  df <- df %>%
    mutate(
      OrigTaxon = Taxon,
      Taxon = sapply(Taxon, newest_taxon)
    ) %>%
    mutate(OrigTaxon = ifelse(OrigTaxon == Taxon, NA, OrigTaxon)) %>%
    relocate(OrigTaxon, .before = Taxon)
  
  update_log <- df %>%
    filter(!is.na(OrigTaxon)) %>%
    select(Date, Station, OrigTaxon, UpdatedTaxon = Taxon)
  
  message('Synonym updates applied: ', nrow(update_log))
  attr(df, 'log') <- list(synonym_updates = update_log)
  return(df)
}

#' @title Combine Taxon Records That Differ by Size or Label Variation
#'
#' @description
#' Aggregates multiple taxon records per sampling event that share the same Date, Station,
#' and Taxon but may differ in size or original labeling. Key numeric columns (e.g., Biovolume_per_mL)
#' are summed within each group. If multiple values of `OrigTaxon` exist, they are collapsed into
#' a single semicolon-separated string. If `OrigTaxon` is `NA`, the corresponding `Taxon` value is used instead.
#' Only one row per unique group is retained after aggregation. A log of combined entries is attached as an attribute.
#'
#' @param df A dataframe containing taxonomic data with columns for Date, Station, Taxon, OrigTaxon, and numeric fields
#'
#' @return A dataframe where taxon rows are aggregated and a 'combined_taxa' log is attached as an attribute
#'
#' @importFrom dplyr group_by ungroup mutate across slice all_of if_else summarise filter
combine_taxons <- function(df) {
  sum_cols <- c('Biovolume_per_mL', 'Units_per_mL', 'Cells_per_mL')
  sum_cols <- intersect(sum_cols, names(df))

  # Identify combinations
  combine_log <- df %>%
    group_by(Date, Station, Taxon) %>%
    summarise(n_combined = n(), .groups = 'drop') %>%
    filter(n_combined > 1)

  # Add combine flag
  df <- df %>%
    group_by(Date, Station, Taxon) %>%
    mutate(
      .combine_group = n() > 1,
      across(all_of(sum_cols), ~ sum(.x, na.rm = TRUE), .names = '{.col}'),
      OrigTaxon = if (.combine_group[1]) {
        paste(
          sort(unique(
            dplyr::if_else(is.na(OrigTaxon), Taxon, OrigTaxon)
          )),
          collapse = '; '
        )
      } else {
        OrigTaxon[1]
      }
    ) %>%
    distinct %>%
    ungroup() %>%
    select(-.combine_group)

  message('Taxon rows combined: ', nrow(combine_log))
  attr(df, 'log') <- list(combined_taxa = combine_log)
  return(df)
}

#' @title Add Higher-Level Taxonomic Information
#'
#' @description
#' Appends hierarchical taxonomy fields (Kingdom, Phylum, Class, AlgalGroup, Genus, Species)
#' to each record based on a reference classification table. Matching is performed using a
#' normalized `PureTaxon` field, which is derived from the `Taxon` column by:
#'
#' - Removing any instance of "cf." (case-insensitive)
#' - Trimming leading/trailing whitespace
#' - Collapsing multiple internal spaces
#' - Converting to lowercase
#'
#' The behavior of the final `Taxon`, `Genus`, and `Species` columns depends on `std_type`:
#'
#' - For `std_type = "program"` (default):
#'   - The original `Taxon` is preserved (e.g., "cf. Genus Species", "Genus cf. Species")
#'   - `Genus` and `Species` are populated from the taxonomy table based on the normalized match
#'
#' - For `std_type = "PESP"`:
#'   - If `Taxon` is of the form "Genus cf. Species", it is standardized to "Genus sp."
#'   - If `Taxon` is "Genus Species cf.", it is normalized to "Genus cf. Species"
#'   - If `Taxon` is "cf. Genus Species", it is standardized to "Unknown <AlgalGroup>" (based on the matched `PureTaxon`),
#'     and `Genus` and `Species` are both set to "Unknown"
#'
#' All taxonomy fields are joined from the `df_syn` reference table using the normalized `PureTaxon`.
#'
#' @param df A dataframe with a `Taxon` column to be enriched with taxonomic metadata
#' @param after_col Column name after which to insert taxonomy fields
#' @param std_type Character; either "program" (default) or "PESP" — controls cf. handling and final naming
#'
#' @return A dataframe with taxonomy columns added (Kingdom, Phylum, Class, AlgalGroup, Genus, Species),
#' and a 'log' attribute containing unmatched taxon records
#'
#' @importFrom dplyr mutate select left_join relocate any_of filter
#' @importFrom stringr str_replace_all str_trim str_detect str_replace
#' @importFrom readr read_csv
higher_lvl_taxa <- function(df, after_col, std_type = 'program') {
  std_type <- tolower(std_type)
  
  df <- df %>%
    mutate(Taxon = stringr::str_trim(Taxon))

  # Normalize "Genus Species cf." → "Genus cf. Species"
  df <- df %>%
    mutate(
      Taxon = dplyr::case_when(
        stringr::str_detect(Taxon, '^\\w+\\s+\\w+\\s+cf\\.$') ~ 
          stringr::str_replace(Taxon, '^(\\w+)\\s+(\\w+)\\s+cf\\.$', '\\1 cf. \\2'),
        TRUE ~ Taxon
      )
    )

  # Handle PESP-specific rules
  df <- df %>%
    mutate(
      cf_genus_species = stringr::str_detect(Taxon, '^cf\\.\\s+\\w+\\s+\\w+$'),
      Taxon = dplyr::case_when(
        std_type == 'pesp' & stringr::str_detect(Taxon, '^\\w+\\s+cf\\.\\s+\\w+$') ~
          stringr::str_replace(Taxon, '^(\\w+)\\s+cf\\.\\s+\\w+$', '\\1 sp.'),
        TRUE ~ Taxon
      )
    )

  # PureTaxon: always remove cf. and normalize
  df <- df %>%
    mutate(
      PureTaxon = stringr::str_replace_all(Taxon, regex('cf\\.', ignore_case = TRUE), ''),
      PureTaxon = stringr::str_trim(PureTaxon),
      PureTaxon = stringr::str_replace_all(PureTaxon, '\\s+', ' '),
      PureTaxon = tolower(PureTaxon)
    )

  # Reference taxonomy
  df_syn <- df_syn %>%
    mutate(
      PureTaxon = stringr::str_trim(CurrentTaxon),
      PureTaxon = stringr::str_replace_all(PureTaxon, '\\s+', ' '),
      PureTaxon = tolower(PureTaxon)
    ) %>%
    select(-Taxon)

  unmatched_log <- df %>%
    filter(!PureTaxon %in% df_syn$PureTaxon) %>%
    select(Date, Station, Taxon, PureTaxon)

  message('Taxa with no match in reference list: ', nrow(unmatched_log))

  df_joined <- df %>%
    left_join(df_syn, by = 'PureTaxon')

  # For PESP + cf. Genus Species: Taxon = "Unknown <AlgalGroup>", Genus = "Unknown", Species = "Unknown"
  df_joined <- df_joined %>%
    mutate(
      Taxon = dplyr::case_when(
        std_type == 'pesp' & cf_genus_species & !is.na(AlgalGroup) ~ paste('Unknown', AlgalGroup),
        TRUE ~ Taxon
      ),
      Genus = dplyr::case_when(
        std_type == 'pesp' & cf_genus_species ~ 'Unknown',
        TRUE ~ Genus
      ),
      Species = dplyr::case_when(
        std_type == 'pesp' & cf_genus_species ~ 'Unknown',
        TRUE ~ Species
      )
    ) %>%
    select(-c(cf_genus_species, PureTaxon, CurrentTaxon)) %>%
    relocate(c(Taxon, Kingdom, Phylum, Class, AlgalGroup), .after = all_of(after_col)) %>%
    relocate(c(Genus, Species), .after = AlgalGroup)

  existing_log <- attr(df, 'log')
  attr(df_joined, 'log') <- c(existing_log, list(unmatched_taxa = unmatched_log))

  return(df_joined)
}
```

```{r}
# Simulated raw input data
df_raw <- tibble::tibble(
  Date = as.Date(c('2023-01-01', '2023-01-01', '2023-01-01','2023-01-01','2023-01-01','2023-01-01','2023-01-01','2023-01-01','2023-01-01')),
  Station = c('A', 'A', 'A','A','A','A','A','A','A'),
  SampleID = c('S1', 'S1', 'S1','S1','S1','S1','S1','S1','S1'),
  Taxon = c('Unknown Diatom 1', 'Navicula spp.', 'Navicula cf. nothing', 'Oscillatoria somethin', 'Aword Wordfour', 'Aword Wordthree', 'Aword Wordtwo', 'omg cf. testing', 'cf. rawr bleh'),
  Biovolume_per_mL = c(1.5, 2.0, 3.1,6,5,7,4,6,5),
  Units_per_mL = c(100, 200, 300,600,250,510,350,230,200)
)

# Simulated typo correction table
df_typos <- tibble::tibble(
  Taxon = c('Unknown Diatom 1'),
  TaxonCorrected = c('Unidentified Diatom')
)

# Simulated synonym table
df_syn <- tibble::tibble(
  Taxon = c('Navicula sp.', 'Naver sp.','Oscillatoria somethin', 'Aword Wordtwo', 'Aword Wordthree', 'Aword Wordfour','omg testing','rawr bleh','Naver nothing','Random somethin','omg sp.','Navicula nothing'),
  CurrentTaxon = c('Naver sp.', 'None', 'Random somethin', 'Aword Wordthree', 'Aword Wordfour','None','None','None','None','None','None','Naver nothing'),
  Kingdom = c('Protista', 'Protista', 'Bacteria', 'Protista','Protista','Protista','Protista','Protista','Protista','Protista','Protista','Protista'),
  Phylum = c('Bacillariophyta', 'Bacillariophyta', 'Cyanobacteria','Cyanobacteria', 'Bacillariophyta','Bacillariophyta','Bacillariophyta','Bacillariophyta','Bacillariophyta','Bacillariophyta','Bacillariophyta','Bacillariophyta'),
  Class = c('Bacillariophyceae', 'Bacillariophyceae', 'Cyanophyceae', 'Bacillariophyceae','Bacillariophyceae','Bacillariophyceae','Bacillariophyceae','Bacillariophyceae','Bacillariophyceae','Bacillariophyceae','Bacillariophyceae','Bacillariophyceae'),
  AlgalGroup = c('Diatoms', 'Diatoms', 'Blue-greens', 'Diatoms','Diatoms','Diatoms','Diatoms','Diatoms','Diatoms','Diatoms','Diatoms','Diatoms'),
  Genus = c('Navicula', 'Naver', 'Random', 'Aword', 'Aword','Aword','omg','rawr','omg','Random','omg','Naver'),
  Species = c('nothing', 'nothing', 'something', 'Wordthree','Wordfour','Wordfour','testing','bleh','nothing','somethin','sp.','nothing')
)

read_quiet_csv <- function(path) {
  readr::read_csv(path, show_col_types = FALSE)
}

# --- Run the workflow ---
df1 <- correct_taxon_typos(df_raw)
df2 <- clean_unknowns(df1)
df3 <- update_synonyms(df2)
df4a <- higher_lvl_taxa(df3, after_col = "SampleID")
df5a <- combine_taxons(df4a)
df4b <- higher_lvl_taxa(df3, after_col = "SampleID",std_type = 'PESP')
df5b <- combine_taxons(df4b)

# --- View Logs ---
attr(df1, 'log')$taxon_corrections
attr(df2, 'log')$clean_unknowns
attr(df3, 'log')$synonym_updates
attr(df4, 'log')$unmatched_taxa
attr(df5, 'log')$combined_taxa
attr(df6, 'log')$unmatched_taxa
attr(df7, 'log')$combined_taxa


standardize_case <- function(x) {
  # Trim and collapse multiple spaces
  x <- stringr::str_trim(x)
  x <- stringr::str_replace_all(x, "\\s+", " ")

  # Handle 'cf.' case separately
  cf_pattern <- "^cf\\.\\s+(\\w+)(.*)$"
  normal_pattern <- "^(\\w+)(.*)$"

  case_fixed <- ifelse(
    stringr::str_detect(x, cf_pattern),
    # If starts with 'cf.', keep it lowercase and format the next word
    paste0(
      "cf.",
      " ",
      stringr::str_match(x, cf_pattern)[, 2] %>% stringr::str_to_title(),
      stringr::str_to_lower(stringr::str_match(x, cf_pattern)[, 3])
    ),
    # Otherwise: capitalize first word, lowercase rest
    paste0(
      stringr::str_to_title(stringr::str_match(x, normal_pattern)[, 2]),
      stringr::str_to_lower(stringr::str_match(x, normal_pattern)[, 3])
    )
  )

  stringr::str_trim(case_fixed)
}

standardize_case("navicula")         # "Navicula"
standardize_case("NAVICULA SP.")     # "Navicula sp."
standardize_case("cf. RAWR BLEH")    # "Cf. rawr bleh"
standardize_case("RAWR cf. BLEH")    # "Cf. rawr bleh"
standardize_case("Oscillatoria somethin")  # "Oscillatoria somethin"
```



## Clean Data

### Change Comments to QA, Add Debris Column
```{r}
# FIX THIS
df_joined <- df_joined %>%
  mutate(
    QC_1 = case_when(grepl('delete|cross contamination', Comments, ignore.case = TRUE) ~ 'BadData'),
    QC_2 = case_when(grepl('did not reach|cannot meet tally|cannot meet natural unit', Comments, ignore.case = TRUE) ~ 'TallyNotMet'),
    QC_3 = case_when(grepl('degraded', Comments, ignore.case = TRUE) ~ 'Degraded'),
    QC_4 = case_when(grepl('poor preservation|poorly preserved|weak preservation|weakly preserved|fungus', Comments, ignore.case = TRUE) ~ 'PoorlyPreserved'),
    QC_5 = case_when(grepl('obscured', Comments, ignore.case = TRUE) ~ 'Obscured'),
    QC_7 = case_when(grepl('broken diatom', Comments, ignore.case = TRUE) & !grepl('broken diatom fragment|fragment\\.', Comments, ignore.case = TRUE) ~ 'BrokenDiatoms')
  ) %>%
  unite(QualityCheck, starts_with('QC'), remove = TRUE, na.rm = TRUE, sep = ' ')

df_joined$QualityCheck[df_joined$QualityCheck == ''] <- 'Good'

# R assigns sequentially, so column priority will always be the "highest" level of debris
df_joined <- df_joined %>%
  mutate(
    Db_1 = case_when(
        grepl('high detritus|high sediment|heavy detritus|heavy sediment', Comments, ignore.case = TRUE) ~ 'high',
        grepl('moderate detritus|moderate sediment', Comments, ignore.case = TRUE) ~ 'moderate',
        grepl('low detritus|low sediment|light detritus|light sediment', Comments, ignore.case = TRUE) ~ 'low')
    ) %>%
    unite(Debris, starts_with('Db'), remove = TRUE, na.rm = TRUE, sep = ' ')
```

### Remove Columns and Duplicates

```{r}
df_joined <- df_joined %>%
  select(-Comments)

check_distinct(df_joined)
```
### Merge with EDI Data

```{r}
df_edi <- get_edi_file(1320, glue::glue('EMP_Phyto_Data_2008-present'))
df_edi <- df_edi[[1]]

colnames(df_edi)

df_edi <- df_edi %>%
  rename(Biovolume_per_mL = AverageBiovolume_per_mL) %>%
  mutate(Debris = NA)

df_edi <- df_edi[,colnames(df_joined)]

df_all <- bind_rows(df_edi, df_joined)

nrow(df_joined)+nrow(df_edi) == nrow(df_all)

# switch date/time to export cols
df_all$Date <- as.character(df_all$Date)
df_all$Time <- as.character(df_all$Time)
```

## Export

```{r}
write_csv(df_all, 'programs/DWR-EMP/generated_data/EMP_Phyto_Data_2008-2023.csv')
```
